<!DOCTYPE HTML>
<html>
	<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Veille technologique &mdash; IA & Fake News</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Free HTML5 Website Template by freehtml5.co" />
	<meta name="keywords" content="free website templates, free html5, free template, free bootstrap, free website template, html5, css3, mobile first, responsive" />
	<meta name="author" content="freehtml5.co" />

	<!-- 
	//////////////////////////////////////////////////////

	FREE HTML5 TEMPLATE 
	DESIGNED & DEVELOPED by FreeHTML5.co
		
	Website: 		http://freehtml5.co/
	Email: 			info@freehtml5.co
	Twitter: 		http://twitter.com/fh5co
	Facebook: 		https://www.facebook.com/fh5co

	//////////////////////////////////////////////////////
	 -->

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<link href="https://fonts.googleapis.com/css?family=Work+Sans:300,400,500,700,800" rel="stylesheet">
	
	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">

	<!-- Magnific Popup -->
	<link rel="stylesheet" href="css/magnific-popup.css">

	<!-- Owl Carousel  -->
	<link rel="stylesheet" href="css/owl.carousel.min.css">
	<link rel="stylesheet" href="css/owl.theme.default.min.css">

	<!-- Theme style  -->
	<link rel="stylesheet" href="css/style.css">

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

    <style>
    .cruise {
        padding-left: 3%;
        padding-right: 3%;
    }
    .cnn_step2 {
        padding-top: 3%;
    }
    </style>
    
	</head>
	<body>
		
	<div class="fh5co-loader"></div>
	
	<div id="page">
	<nav class="fh5co-nav" role="navigation">
		<div class="top">
			<div class="container">
				<div class="row">
					<div class="col-xs-12 text-right">
						<ul class="fh5co-social">
							<li><a href="https://www.diigo.com/user/hugomailfait"><b>Diigo</b></i></a></li>
							<li><a href="https://github.com/HugoMailfait"><b>Github</b></i></a></li>
							<li><a href="https://www.linkedin.com/in/hugo-mailfait-b92105160/"><b>LinkedIn</b></i></a></li>
						</ul>
					</div>
				</div>
			</div>
		</div>
		<div class="top-menu">
			<div class="container">
				<div class="row">
					<div class="col-xs-1">
						<div id="fh5co-logo"><a href="index.html"><b>VTECL</b><span>.</span></a></div>
					</div>
					<div class="col-xs-11 text-right menu-1">
						<ul>
							<li><a href="index.html">Accueil</a></li>
							<li><a href="nlp.html">Traitement du langage</a></li>
							<li class="active"><a href="deepfakes.html">Etude des DeepFakes</a></li>
							<li><a href="difficulties.html">Une guerre perdue d'avance ?</a></li>
						</ul>
					</div>
				</div>
				
			</div>
		</div>
	</nav>

	<header id="fh5co-header" class="fh5co-cover fh5co-cover-sm" role="banner" style="background-image:url(images/img_bg_2.jpg);" data-stellar-background-ratio="0.5">
		<div class="overlay"></div>
		<div class="container">
			<div class="row">
				<div class="col-md-8 col-md-offset-2 text-center">
					<div class="display-t">
						<div class="display-tc animate-box" data-animate-effect="fadeIn">
							<h1>Les réseaux de convolution face à l’explosion des DeepFakes</h1>
						</div>
					</div>
				</div>
			</div>
		</div>
	</header>

    <div id="fh5co-explore" class="fh5co-bg-section">
	
		<div class="fh5co-explore fh5co-explore1">
			<div class="container">
				<div class="row">
					<div class="animate-box">
						<div class="mt">
							<h3>Qu'est-ce qu'un DeepFake ?</h3>
							<p align="justify">Le terme DeepFake provient de la combinaison des termes « deep learning » et « fake ». Concrètement, il s’agit d’une technologie qui utilise des réseaux de neurones et d’autres techniques d’intelligence artificielle pour créer des vidéos réalistes de choses qui ne le sont pas. L’objectif est alors d’induire en erreur les personnes visionnant la vidéo et de les influencer.  </p>							
						</div>
					</div>
				</div>
				<div class="row">
					<div class="col-md-6 animate-box">
    					<div class="cruise">
    						<img class="img-responsive" src="images/img_cruise.jpg" alt="work">
    					</div>	
					</div>
					<div class="col-md-6 animate-box">
						<p align="justify">Une forme très répandue depuis plusieurs années des deepfakes est la possibilité de remplacer le visage de personnes sur des vidéos par d’autres, pour leur attribuer des propos qu’ils n’ont pas tenu et les discréditer aux yeux de l’opinion publique. Ces attaques prennent généralement pour cibles des personnalités politiques ou des célébrités.  </p>
						<p align="justify">Pour alerter sur ce phénomène, un belge a notamment créé un compte sur le réseau social TikTok fin février et publié des vidéos de Tom Cruise montée de toutes pièces par un algorithme. </p>
					</div>
				</div>
			</div>
		</div>
		
		<div class="fh5co-explore fh5co-explore1">
			<div class="container">
				<div class="row">
					<div class="col-md-6 animate-box">
						<h3>DeepFake Detection Challenge</h3>
						<p align="justify">En 2020, une compétition organisée par FaceBook a rassemblé 2000 participants pour mettre en place des solutions innovantes de détection de deepfakes. A cette occasion, les organisateurs avaient préparé un dataset de 100 000 vidéos, parmi lesquelles de nombreuses ont été tournées spécifiquement pour l’évènement. De plus, un nombre important de transformations différentes ont été appliquées pour rendre le jeu de données le plus exhaustif possible. Par exemple, des images aléatoires ont été ajoutées à certaines vidéos, les résolutions trafiquées, des contrastes modifiés etc …  </p>							
					</div>
					<div class="col-md-6 animate-box">
    					<img class="img-responsive" src="images/img_challenge.jpg" alt="work">
					</div>
				</div>
			</div>
			
			<div class="container">
            	<div class="row">
       				<div class="animate-box">
   						<div class="cnn_step2">
   							<p align="justify">L’étude des résultats et des programmes développés propose plusieurs pistes intéressantes communes aux meilleurs détecteurs. Par exemple, de nombreux candidats ont procédé à une augmentation des données en modifiant des morceaux d’images, de manière aléatoire ou en utilisant des mécanismes d’attention. Certaines augmentations de données reposaient sur l’assemblage de visages réels et générés par une IA. Il est amusant de noter qu’aucun candidat n’a utilisé de technique scientifique basée sur des capteurs physiques de bruit ou d’autres technologies habituelles de la génération d’images. Enfin, les meilleurs projets ont tous utilisés des réseaux pré-entraînés EfficientNet, les différences entre les candidats étant leur nombre et les méthodes de combinaison employées.  </p>
       						<p align="justify">L’identification de ces caractéristiques communes pourrait permettre aux chercheurs de Facebook d’améliorer significativement leurs modèles, en s’inspirant des meilleures méthodes et en étudiant les idées novatrices proposées. Cependant, il est important de noter que les résultats ne dépassent pas 70% de réussite sur les nouvelles deepfakes proposées pour la phase de test finale. La recherche avance mais de nombreux progrès restent à faire. </p>
                            <p align="justify">Par ailleurs, la communauté des chercheurs considère qu’une amélioration de la détection des deepfakes en ligne ne passe pas uniquement par l’étude des images et de leur enchaînement dans la vidéo, mais également par un travail autour de la provenance, du contexte social et politique au moment de la vidéo etc …  </p>
   					 	</div>
   					</div>
                </div>
            </div>
		</div>
		
	</div>

	<div id="fh5co-project">
    	<div class="fh5co-explore fh5co-explore1">
    	
    		<div class="container">
            	<div class="row">
                	<div class="col-md-1 animate-box">
                	</div>
       				<div class="col-md-10 animate-box">
   						<div>
       						<h3>La détection par les artéfacts :</h3>
   							<p align="justify">Cette étude s’intéresse spécifiquement aux deepfakes dans lesquelles le visage d’un être humain est remplacé par un autre. Comme indiqué précédemment, les mécanismes de réseaux de neurones utilisés permettent de conserver les expressions faciales. Cependant, dans de nombreux cas, ce mécanisme laisse de nombreux artéfacts sur l’image. Ceux-ci sont indétectables à l’œil nu mais peuvent l’être grâce à des algorithmes de machine learning particuliers. </p>
       						<p align="justify">Les artéfacts de ces images proviennent des déformations apportées au visage synthétisé pour le faire correspondre au visage source. En effet, cette transformation modifie la résolution de l’image au niveau des bords du visage. </p>
                            <p align="justify">L’étude est menée à partir d’un jeu de données d’entraînement de plus de 24 000 visages disponibles sur Internet. Pour obtenir les images truquées, on ne remplace pas les visages par d’autres mais on cherche à ajouter les artéfacts.  </p>
                            <p align="justify">Plus précisément, l’opération consiste tout d’abord à détecter le visage sur l’image grâce à des réseaux de neurones puis à l’extraire. Ensuite, des modifications pseudo-aléatoires sont apportées au visage sur l’éclairage et sa résolution pour modéliser un maximum de cas possibles. Enfin, la transformation affine du visage est réalisée et ce dernier est alors replacé sur son image d’origine avec un lissage sur les frontières pour plus de réalisme. </p>
                            <img class="img-responsive" src="images/img_cnn_faces.JPG" alt="work">
   					 	</div>
   					</div>
   					<div class="col-md-1 animate-box">
                	</div>
                </div>
            </div>
            
            <div class="container">
            	<div class="row">
                	<div class="cnn_step2">
                    	<div class="col-md-1 animate-box">
                    	</div>
           				<div class="col-md-10 animate-box">
       						<div>
       							<p align="justify">Ensuite, l’objectif est d’entraîner 4 réseaux de convolution pré-entraînés différents avec nos données d’entrée. Ainsi, lors de la phase de tests avec de nouvelles données, les réseaux pourront renvoyer une probabilité d’avoir affaire à une vidéo truquée.  </p>
           						<p align="justify">Pour cela, on ne conserve pas l’intégralité de l’image mais seulement des régions dites d’intérêt, de formes carrées. Ces régions doivent à la fois contenir les visages et une partie de l’environnement nécessaire à la détection du trucage. Ces zones sont ensuite transformées en images de 224x224 pixels pour les besoins des CNN.  </p>
                                <p align="justify">Par ailleurs, le batch size est fixé à 64, le taux d’apprentissage à 0.001 avec un decay de 0.95 toutes les 1000 étapes et l’optimisation est réalisée par SGD.   </p>
                                <p align="justify">Là encore, l’évaluation des résultats se fait par rapport aux autres algorithmes disponibles sur le marché. On retrouve notamment 3 méthodes différentes : Two-Stream NN, MesoNet et HeadPose. Par ailleurs, les jeux de données pour l’évaluation sont UAFDV, un ensemble de 98 vidéos de 11 secondes avec une seule personne dont la moitié comporte des trucages, et DeepFake TIMIT, où le nombre de sujets sur les vidéos est plus important et où des qualités de résolution différentes sont disponibles (LQ et HQ). On obtient les résultats ci-contre : </p>
    					 	</div>
       					</div>
           				<div class="col-md-1 animate-box">
                    	</div>
       				</div>	
                </div>
            </div>
            
            <div class="container">
            	<div class="row">
                	<div class="col-md-7 animate-box">
       					<img class="img-responsive" src="images/img_cnn_2_1.JPG" alt="work">
   					</div>
   					<div class="col-md-5 animate-box">
       					<img class="img-responsive" src="images/img_cnn_2_2.JPG" alt="work">
   					</div>
                </div>
            </div>
            
            <div class="container">
            	<div class="row">
                	<div class="cnn_step2">
                    	<div class="col-md-1 animate-box">
                    	</div>
           				<div class="col-md-10 animate-box">
       						<div>
       							<p align="justify">Comme illustré dans le tableau des résultats, les modèles ResNet présentent de meilleures performances que les autres méthodes de l’état de l’art. En particulier, le réseau ResNet50 surpasse l’ensemble des autres propositions, avec par exemple des résultats 16% plus précis que la méthode Two-Stream NN sur les deux jeux de données. De plus, on note que sur les vidéos en haute qualité de DeepFake TIMIT, les résultats sont bien supérieurs. Cela s’explique par la possibilité d’un sur-apprentissage pour MesoNet par exemple.  </p>
           						<p align="justify">L’objectif du projet est donc de poursuivre l’amélioration de la méthode et sa robustesse, en ajoutant par exemple une compression des vidéos. Dans un second temps, les chercheurs souhaitent construire de nouveaux réseaux de convolution spécifiques à cet usage pour observer l’impact sur la détection. </p>
    					 	</div>
       					</div>
           				<div class="col-md-1 animate-box">
                    	</div>
       				</div>	
                </div>
            </div>
            
    	</div>
	</div>
	
	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-arrow-up"></i></a>
	</div>
	
	<!-- jQuery -->
	<script src="js/jquery.min.js"></script>
	<!-- jQuery Easing -->
	<script src="js/jquery.easing.1.3.js"></script>
	<!-- Bootstrap -->
	<script src="js/bootstrap.min.js"></script>
	<!-- Waypoints -->
	<script src="js/jquery.waypoints.min.js"></script>
	<!-- Stellar Parallax -->
	<script src="js/jquery.stellar.min.js"></script>
	<!-- Carousel -->
	<script src="js/owl.carousel.min.js"></script>
	<!-- countTo -->
	<script src="js/jquery.countTo.js"></script>
	<!-- Magnific Popup -->
	<script src="js/jquery.magnific-popup.min.js"></script>
	<script src="js/magnific-popup-options.js"></script>
	<!-- Main -->
	<script src="js/main.js"></script>

	</body>
</html>

