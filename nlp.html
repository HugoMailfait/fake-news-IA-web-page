<!DOCTYPE HTML>
<html>
	<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Veille technologique &mdash; IA & Fake News</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Free HTML5 Website Template by freehtml5.co" />
	<meta name="keywords" content="free website templates, free html5, free template, free bootstrap, free website template, html5, css3, mobile first, responsive" />
	<meta name="author" content="freehtml5.co" />

	<!-- 
	//////////////////////////////////////////////////////

	FREE HTML5 TEMPLATE 
	DESIGNED & DEVELOPED by FreeHTML5.co
		
	Website: 		http://freehtml5.co/
	Email: 			info@freehtml5.co
	Twitter: 		http://twitter.com/fh5co
	Facebook: 		https://www.facebook.com/fh5co

	//////////////////////////////////////////////////////
	 -->

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<link href="https://fonts.googleapis.com/css?family=Work+Sans:300,400,500,700,800" rel="stylesheet">
	
	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">

	<!-- Magnific Popup -->
	<link rel="stylesheet" href="css/magnific-popup.css">

	<!-- Owl Carousel  -->
	<link rel="stylesheet" href="css/owl.carousel.min.css">
	<link rel="stylesheet" href="css/owl.theme.default.min.css">

	<!-- Theme style  -->
	<link rel="stylesheet" href="css/style.css">

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

    <style>
    .nlp {
        padding-right: 5%;
        padding-top: 5%;
    }
    .bow {
        padding-top: 3%;
    }
    .tree {
        padding-left: 15%;
        padding-bottom: 3%;
    }
    
    .ex1-1 {
        padding-bottom: 3%;
    }
    .ex1-2 {
        padding-top: 8%;
    }

    .ex1-3 {
        padding-left: 5%;
    }
    .ex1-4 {
        padding-top: 4%;
    }
    
    .ex2-1 {
        padding-top: 10%;
    }
    
    .features_txt {
        padding-top: 8%;
    }
    
    .features_img {
        padding-left: 10%;
        padding-bottom: 2%;
    }
    
    .end_nlp {
        padding-top: 3%;
    }
    
    </style>
	</head>
	<body>
		
	<div class="fh5co-loader"></div>
	
	<div id="page">
	<nav class="fh5co-nav" role="navigation">
		<div class="top">
			<div class="container">
				<div class="row">
					<div class="col-xs-12 text-right">
						<ul class="fh5co-social">
							<li><a href="https://www.diigo.com/user/hugomailfait"><b>Diigo</b></i></a></li>
							<li><a href="https://github.com/HugoMailfait"><b>Github</b></i></a></li>
							<li><a href="https://www.linkedin.com/in/hugo-mailfait-b92105160/"><b>LinkedIn</b></i></a></li>
						</ul>
					</div>
				</div>
			</div>
		</div>
		<div class="top-menu">
			<div class="container">
				<div class="row">
					<div class="col-xs-1">
						<div id="fh5co-logo"><a href="index.html"><b>VTECL</b><span>.</span></a></div>
					</div>
					<div class="col-xs-11 text-right menu-1">
						<ul>
							<li><a href="index.html">Accueil</a></li>
                            <li class="active"><a href="nlp.html">Traitement du langage</a></li>
							<li><a href="deepfakes.html">Etude des DeepFakes</a></li>
							<li><a href="difficulties.html">Une guerre perdue d'avance ?</a></li>
						</ul>
					</div>
				</div>
				
			</div>
		</div>
	</nav>

	<header id="fh5co-header" class="fh5co-cover fh5co-cover-sm" role="banner" style="background-image:url(images/img_bg_2.jpg);" data-stellar-background-ratio="0.5">
		<div class="overlay"></div>
		<div class="container">
			<div class="row">
				<div class="col-md-8 col-md-offset-2 text-center">
					<div class="display-t">
						<div class="display-tc animate-box" data-animate-effect="fadeIn">
							<h1>Le NLP appliqué à la détection de propos mensongers</h1>
						</div>
					</div>
				</div>
			</div>
		</div>
	</header>

	<div id="fh5co-explore" class="fh5co-bg-section">
	
		<div class="fh5co-explore fh5co-explore1">
			<div class="container">
				<div class="row">
					<div class="col-md-6 animate-box">
    					<div class="nlp">
    						<img class="img-responsive" src="images/img_nlp.png" alt="work">
    					</div>	
					</div>
					<div class="col-md-6 animate-box">
						<div class="mt">
							<h3>Généralités</h3>
							<p align="justify">Le traitement naturel du langage, ou <i>Natural Language Processing</i> (NLP) en anglais, est une technologie d’intelligence artificielle permettant aux machines d’appréhender le langage humain. Cela permet notamment de lire, de comprendre et de générer du langage humain. </p>
							<p align="justify">Dans le cadre de l’IA, la détection de fake news sur les réseaux sociaux ou dans les articles de presse se présente comme une évaluation des chances que les propos étudiés soient intentionnellement composés de fausses informations. </p>
							
						</div>
					</div>
				</div>
			</div>
		</div>

		<div class="fh5co-explore fh5co-explore1">
			<div class="container">
				<div class="row">
    				<div class="animate-box">
                        <h3>L'approche linguistique</h3>
                        <p align="justify">Deux grandes méthodes se distinguent dans les projets de recherche sur le sujet. La première consiste en une approche linguistique, dans laquelle le contenu des messages est étudié précisément pour savoir s’il contient les patterns habituels des fake news.  </p>
        			</div>
        		</div>
        		<div class="row">
					<div class="col-md-6 animate-box">
						<div>
							<p align="justify">La technique la plus simple est de représenter le texte via des « bag-of-words ». Concrètement, le contenu des phrases est décrit par une ou plusieurs matrices contenant des informations sur la fréquence des mots. Cependant, cette méthode isole chaque élément du texte : les informations de contexte ne sont donc pas prises en compte, tout comme l’ambiguïté des tournures de phrases. </p>
						</div>
					</div>
					<div class="col-md-6 animate-box">
    					<div class="bow">
        					<img class="img-responsive" src="images/img_bow.png"  alt="work">
        				</div>
					</div>
				</div>
				<div class="row">
					<div class="col-md-6 animate-box">
    					<div class="tree">
        					<img class="img-responsive" src="images/img_parse_tree.png"  alt="work">
        				</div>
					</div>
					<div class="col-md-6 animate-box">
						<div>
							<p align="justify">Pour pallier à ce problème, la syntaxe des phrases peut elle aussi être étudiée. Des arborescences de structure grammaticale peuvent être construites et des probabilités sont alors assignées à cet arbre. Par exemple, on pourrait remarquer que pour un document, la probabilité qu’un groupe nominal soit composé d’un déterminant et d’un nom est de 0.37, de 0.29 pour deux groupes nominaux, etc ... Les fake news présentent souvent des différences notables avec les arbres syntaxiques des vraies informations. D’après une étude de 2012, le taux de réussite de cette méthode oscille entre 85% et 91%, selon les méthodologies choisies pour la construction des arbres.  </p>
						</div>
					</div>

				</div>
				<div class="row">
    				<div class="animate-box">
                        <p align="justify">Enfin, de nombreuses autres techniques existent et présentent des résultats très intéressants également. On peut notamment citer l’étude des contradictions et des omissions dans un article, ou encore l’analyse de sentiments des fake news qui révèle une présence significative de propos à connotation négative. </p>
        			</div>
        		</div>
			</div>
		</div>
		
		<div class="fh5co-explore fh5co-explore1">
			<div class="container">
				<div class="row">
					<div class="animate-box">
						<h3>L'approche réseau</h3>
						<p align="justify">Une seconde grande méthode de détection des fake news repose sur l’exploitation et l’étude du canal de diffusion de l’information et des données disponibles en ligne. </p>
						<p align="justify">En effet, les fake news sur les réseaux sociaux associent généralement deux « concepts » et affirment qu’un lien existe entre eux. Ainsi, pour vérifier si une information est fiable, il est possible d’utiliser des réseaux de connaissance pour évaluer cette connexion. L’idée est de construire le chemin le plus simple et le plus court pour arriver d’une entité à une autre sur ce réseau de connaissances. Des mesures de la probabilité de passage d’un nœud au suivant sont ensuite calculées : si ces probabilités sont faibles, il est probable que l’information présentée soit fausse.  </p>
						<p align="justify">D’après une étude sur 4 thématiques différentes, la précision de la méthode est comprise entre 61% et 95%. Néanmoins, cette technologie est complexe à implémenter car elle repose sur l’existence de réseaux de connaissance fiables et complets pour la construction du chemin. </p>
					</div>
				</div>
			</div>
		</div>
	</div>

	<div id="fh5co-project">
    	<div class="fh5co-explore fh5co-explore1">
    	
    		<div class="container">
    			<div class="ex1-1">
            		<div class="row">
       					<div class="col-md-6 animate-box">
       						<div>
           						<h3>Un premier exemple</h3>
       							<p align="justify">Dans la suite, on s’intéressera à deux études précises pour lesquelles on détaillera les technologies employées et les résultats obtenus.</p>
           						<p align="justify">Le premier exemple proposé consiste en la détection de titres mensongers par rapport au contenu de l’article. La base de données utilisée est composée de ces articles, de leurs titres et d’une évaluation de leur degré de correspondance.</p>
       						</div>
       					</div>
       					<div class="col-md-6 animate-box">
               				<img class="img-responsive" src="images/img_nlp_ex1_1.JPG"  alt="work">
       					</div>
    				</div>
                </div>
            </div>
            
            <div class="container">
				<div class="row">
					<div class="col-md-6 animate-box">
       					<div class="ex1-2">
           					<img class="img-responsive" src="images/img_nlp_ex1_2.JPG"  alt="work">
       				    </div>
   					</div>
   					<div class="col-md-6 animate-box">
						<div>
							<p align="justify">Cette étude repose sur la comparaison de différentes méthodes pour classifier correctement les titres vis-à-vis du contenu des articles. On commencera par présenter la méthode avec les meilleurs résultats.  Dans ce cas précis, il s’agit du calcul de vecteurs TF-IDF (Term-Frequency Inverse-Document-Frequency) et de l’utilisation d’un réseau de neurones. </p>
    						<p align="justify">Tout d’abord, avant tout calcul, une étape de pre-processing est requise. Dès lors, le titre et le contenu de l’article sont décomposés en 2 vecteurs différents. Pour chacun d’eux, on sépare les mots les uns des autres, on retire la ponctuation et les mots non significatifs. Un stemming est également réalisé pour n’obtenir que la racine des mots et ainsi n’avoir qu’un seul terme pour les mots étymologiquement proches. </p>
						</div>
					</div>
				</div>
			</div>
			
			<div class="container">
            	<div class="row">
   					<div class="animate-box">
   						<div>
   							<p align="justify">Vient ensuite l’étape du calcul des deux vecteurs TF-IDF, l’un pour le titre, l’autre pour le contenu de l’article. Il s’agit de transformer la liste obtenue en une donnée quantifiable. Plus précisément, on attribue à chaque mot présent dans le corpus un poids qui évalue son importance dans le document. Ce poids augmente lorsque le mot apparaît très fréquemment dans le document et peu ailleurs. </p>
   						</div>
   					</div>
                </div>
            </div>
            
            <div class="container">
        		<div class="row">
   					<div class="col-md-4 animate-box">
   						<div>
   							<p align="justify">Enfin, la dernière étape consiste à concaténer les paires de vecteur TF-IDF titre-contenu et leur cos-similarité (méthode de calcul de similarité entre 2 vecteurs non nuls) et à passer cet ensemble dans un réseau de neurones. Le dernier étage du réseau renvoie la probabilité d’appartenir à chacune des 4 classes. Les hyperparamètres du modèle (fonctions d’activation, dropout, L2 penalty …) ont été choisis pour obtenir le meilleur résultat possible.</p>
       					</div>
   					</div>
   					<div class="col-md-8 animate-box">
       					<div class="ex1-3">
               				<img class="img-responsive" src="images/img_nlp_ex1_3.JPG"  alt="work">
               			</div>	
   					</div>
                </div>
            </div>
            
            <div class="container">
                <div class="ex1-4">
    				<div class="row">
    					<div class="col-md-6 animate-box">
               				<img class="img-responsive" src="images/img_nlp_ex1_4.JPG"  alt="work">
       					</div>
       					<div class="col-md-6 animate-box">
    						<div>
    							<p align="justify">Deux autres essais ont également été réalisés : l’un avec de simples « Bag-Of-Words » et l’autre à l’aide d’un algorithme pré-entraîné de représentation de mots dans un espace vectoriel, à savoir Word2Vec de Google. Cet algorithme attribue à chaque mot un vecteur de dimension 300, qui le représente parmi l’ensemble des mots du corpus. Comme illustré sur la figure ci-contre, les résultats sont moins bons. </p>
        						<p align="justify">Pour la méthode TF-IDF, la précision de la classification générale est de 94.3%, contre 89.2% pour le « Bag-of-Words » et 75.7% pour l’utilisation de Word2Vec. Ls résultats semblent excellents mais en observant la matrice de confusion précisément, on remarque que les erreurs de classification pour ‘Agree’ et ‘Disagree’ sont importants. La simplicité des méthodes envisagées et testées ne permet pas d’obtenir de meilleures évaluations. </p>
    						</div>
    					</div>
    				</div>
    			</div>
            </div>
            
		</div>
    </div>
    
    <div id="fh5co-project">
    
    	<div class="fh5co-explore fh5co-explore1">
    	
    		<div class="container">
        		<div class="row">
   					<div class="animate-box">
   						<div>
       						<h3>Le framework FAKEDETECTOR</h3>
   							<p align="justify">Ce deuxième sujet d’étude s’intéresse aux différentes corrélations entre les articles « fake news », leurs créateurs et le sujet traité. Ce projet a pour ambition d’éradiquer le plus possible de fausses informations à long terme en remontant à la source du problème via l’étude du sujet et du créateur. Pour cela, l’algorithme cherche à attribuer un score de crédibilité aux articles, créateurs et sujets étudiés. Concrètement, l’objectif est de concevoir une fonction f capable de prédire la crédibilité des articles d’un set N, des auteurs d’un set U et des sujets d’un set S. </p>
       						<p align="justify">Ce score repose sur un modèle de deep learning et la recherche de features explicites et implicites dans les différents cas. La base de données utilisée pour l’apprentissage, la validation et le test est composée d’articles et de tweets rassemblés et évalués par Politifact. </p>
   						</div>
   					</div>
                </div>
            </div>
            
            <div class="container">
				<div class="row">
					<div class="col-md-6 animate-box">
    					<div class="ex2-1">
               				<img class="img-responsive" src="images/img_nlp_ex2_1.JPG"  alt="work">
               			</div>
   					</div>
   					<div class="col-md-6 animate-box">
						<div>
							<p align="justify">La première étape de l’étude est l’analyse statistique des données rassemblées par Politifact. Par exemple, l’étude du contenu des articles révèle que certains mots sont beaucoup plus fréquemment utilisés dans les articles mensongers que dans les informations avérées. De même, en regroupant les créateurs d’articles selon différentes appartenances, il est possible de dresser des tendances pour certains groupes de populations. Par exemple, les hommes politiques républicains auront plus de dispositions à partager de fausses informations que les femmes démocrates.  Enfin, certains sujets sont également plus susceptibles de contenir des contre-vérités (terrorisme, santé …) que d’autres (économie …). </p>
						</div>
					</div>
				</div>
            </div>
            
            <div class="container">
        		<div class="row">
   					<div class="animate-box">
   						<div>
   							<p align="justify">En poussant l’analyse statistique précédente, il est alors possible d’extraire un ensemble W de mots ou de séquence de mots qui présentent une corrélation significative avec le caractère véridique ou mensonger d’un article, d’un sujet ou d’un créateur. Ces éléments sont appelés des <i>explicit features</i>. </p>
   						</div>
   					</div>
                </div>
            </div>
        
            <div class="container">
				<div class="row">
   					<div class="col-md-6 animate-box">
						<div>
    						<div class="features_txt">
    							<p align="justify">Dans un second temps, on s’intéresse aux patterns implicites. Pour les extraire et les exploiter dans notre classification, on utilise un réseau de neurones récurrent à 3 couches, dans lequel chacun des articles en entrée est représenté par un vecteur de dimension fixe. La couche cachée est une Gated Reccurent Unit (GRU), dont l’intérêt est de pouvoir conserver beaucoup d’information en amont du mot étudié pour mieux en comprendre le contexte. L’ensemble de ces deux analyses constitue le HLFU, à savoir l’<i>hybrid feature extraction unit</i>. </p>
                            </div>						
						</div>
					</div>
					<div class="col-md-6 animate-box">
    					<div class="features_img">
               				<img class="img-responsive" src="images/img_features.JPG"  alt="work">
               			</div>
   					</div>
				</div>
            </div>
            
            <div class="container">
        		<div class="row">
   					<div class="animate-box">
   						<div>		
           					<p align="justify">Pour rappel, le score de crédibilité d’un article est fortement corrélé au sujet débattu et à son origine, son créateur. Des relations existent notamment entre ces trois différentes entités. </p>
                            <p align="justify">Pour modéliser ces liens, on utilise un modèle de Gated Diffusive Unit. Pour un article précis, le GDU prend en arguments les <i>features</i> implicites et explicites établis précédemment et les GDUs correspondant aux sujets et aux créateurs. Il renvoie un vecteur d’état noté <i>hi</i>, que l’on multiplie alors par une matrice de pondération spécifique aux articles et auquel on applique ensuite la fonction <i>softmax</i> pour obtenir un score de crédibilité de l’article. En réalisant de même pour chaque autre article et tous les sujets et créateurs, il apparaît possible de déterminer si une affirmation est véridique ou erronée. </p>   						
   						</div>
   					</div>
                </div>
            </div>
            
            <div class="container">
				<div class="row">
    				<div class="col-md-2 animate-box">
    				</div>
					<div class="col-md-4 animate-box">
               			<img class="img-responsive" src="images/img_gdu.JPG"  alt="work">
   					</div>
					<div class="col-md-4 animate-box">
               			<img class="img-responsive" src="images/img_architecture.JPG"  alt="work">
   					</div>
				</div>
            </div>
            
            <div class="container">
        		<div class="row">
            		<div class="end_nlp">
       					<div class="animate-box">
       						<div>		
               					<p align="justify">L’analyse des résultats de cette méthode est réalisée comparativement avec d’autres algorithmes et frameworks. On retrouve notamment un modèle de réseaux de convolution hybride de WY Wang en 2017, le framework TRIFN qui définit des relations entre articles, utilisateurs et diffuseurs ou encore des méthodes simples de RNN et de clustering SVM. </p>
                                <p align="justify">Pour une sortie composée de 2 classes, le framework FakeDetector obtient une précision de 0.63, soit un score supérieur de plus de 14% aux autres méthodes de l’état de l’art. Toutefois, sur le critère du rappel, le framework ne surpasse pas particulièrement les autres.  </p>   						
                                <p align="justify">Pour correspondre aux classifications proposées par Politifact, un modèle à 6 classes de sortie a également été testé. Cela permet un meilleur niveau de granularité et d’éviter une binarité des résultats parfois non pertinente. Avec ces 6 classes, la précision descend à 0.28, mais elle est maintenant 40% supérieure aux résultats des autres méthodes ! </p>   						
       						</div>
       					</div>
       				</div>	
                </div>
            </div>
        </div>

	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-arrow-up"></i></a>
	</div>
	
	<!-- jQuery -->
	<script src="js/jquery.min.js"></script>
	<!-- jQuery Easing -->
	<script src="js/jquery.easing.1.3.js"></script>
	<!-- Bootstrap -->
	<script src="js/bootstrap.min.js"></script>
	<!-- Waypoints -->
	<script src="js/jquery.waypoints.min.js"></script>
	<!-- Stellar Parallax -->
	<script src="js/jquery.stellar.min.js"></script>
	<!-- Carousel -->
	<script src="js/owl.carousel.min.js"></script>
	<!-- countTo -->
	<script src="js/jquery.countTo.js"></script>
	<!-- Magnific Popup -->
	<script src="js/jquery.magnific-popup.min.js"></script>
	<script src="js/magnific-popup-options.js"></script>
	<!-- Main -->
	<script src="js/main.js"></script>

	</body>
</html>

